{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKbTfOgafn0x"
      },
      "source": [
        "### MATH4480 Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_lPnA4Enbj-"
      },
      "source": [
        "This final project intends to do a sentiment classification on Amazon reviews under the catagory of \"Software\". The analysis can also apply to other catagory. The reason to choose \"Software\" is because of its relatively small size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90Sh_9jIntKl"
      },
      "source": [
        "Import necessary tools and packages for the analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB52-G8ofhj1",
        "outputId": "93b5270e-8534-4ca4-b9d4-c5d032ade8ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup  \n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from collections import defaultdict\n",
        "from keras.layers.convolutional import Convolution1D\n",
        "from keras import backend as K\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet, stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "\n",
        "import logging\n",
        "from gensim.models import word2vec\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EblHH0eMf2o6"
      },
      "source": [
        "Download the dataset directly from the amazon AWS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnFBTpIPoFPO"
      },
      "source": [
        "The dataset in the tensorflow repository has complicated structures that is hard to convert to dataframe in Pandas. (Something called prefetch dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dynY-d90DjEY",
        "outputId": "3837ab9e-be87-49ab-e5ad-552545009e1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-06 05:21:35--  https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Software_v1_00.tsv.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 3.5.6.123\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|3.5.6.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94010685 (90M) [application/x-gzip]\n",
            "Saving to: ‘amazon_reviews_us_Software_v1_00.tsv.gz.1’\n",
            "\n",
            "amazon_reviews_us_S 100%[===================>]  89.66M  42.5MB/s    in 2.1s    \n",
            "\n",
            "2022-05-06 05:21:38 (42.5 MB/s) - ‘amazon_reviews_us_Software_v1_00.tsv.gz.1’ saved [94010685/94010685]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Software_v1_00.tsv.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMeDezKDoJ1-"
      },
      "source": [
        "The download dataset is zipped, so I used gzip to unzip the data into a TSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laREUkQ4Gkz0"
      },
      "outputs": [],
      "source": [
        "data = gzip.open('amazon_reviews_us_Software_v1_00.tsv.gz')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syrcr0M9oUlB"
      },
      "source": [
        "Then I read the file using pandas' read_csv. The error_bad_lines omitted some lines that may cause error. (Probably caused by some redundent space in the file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWvZ1RLPJfNR",
        "outputId": "2f6160c6-1245-43ae-944b-f54679de21b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "b'Skipping line 8021: expected 15 fields, saw 22\\nSkipping line 34886: expected 15 fields, saw 22\\nSkipping line 49286: expected 15 fields, saw 22\\n'\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(data, sep='\\t',error_bad_lines = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E5oVpJupNcH"
      },
      "source": [
        "We can check the first 5 rows of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "6KRMrS5zfrpO",
        "outputId": "a925a827-079a-44b6-8f47-b60a9c47df80"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8974fe05-862b-43f9-91a4-2d25c5fb192b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>42605767</td>\n",
              "      <td>R3EFW2STIYIY0I</td>\n",
              "      <td>B00MUTIDKI</td>\n",
              "      <td>248732228</td>\n",
              "      <td>McAfee 2015 Internet Security 3 PC (3-Users)</td>\n",
              "      <td>Software</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>I was very disappointed with this</td>\n",
              "      <td>I was very disappointed with this. The descrip...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>51771800</td>\n",
              "      <td>R12NR0R5A9F7FT</td>\n",
              "      <td>B00EPACNUG</td>\n",
              "      <td>531462352</td>\n",
              "      <td>Hallmark Card Studio 2014</td>\n",
              "      <td>Software</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>I had a little struggle getting familiarized, ...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>16053526</td>\n",
              "      <td>R1LSH74R9XAP59</td>\n",
              "      <td>B00164AZA4</td>\n",
              "      <td>473982505</td>\n",
              "      <td>Search and Rescue 4</td>\n",
              "      <td>Software</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Have windows 10?</td>\n",
              "      <td>Tried to download it on my Windows 10 and it w...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>15319481</td>\n",
              "      <td>R1QXUNTF76K7L6</td>\n",
              "      <td>B00E6LIEFM</td>\n",
              "      <td>189774198</td>\n",
              "      <td>Quickbooks Pro</td>\n",
              "      <td>Software</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Disc was corrupt, had to spend a couple hours ...</td>\n",
              "      <td>Disc was corrupt, had to spend a couple hours ...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>1441820</td>\n",
              "      <td>R2F7DR75PS8NKT</td>\n",
              "      <td>B00VWEBG06</td>\n",
              "      <td>852470365</td>\n",
              "      <td>Windows 7 Professional with Service Pack 1 (64...</td>\n",
              "      <td>Software</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Just what I needed. Took a little longer to sh...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8974fe05-862b-43f9-91a4-2d25c5fb192b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8974fe05-862b-43f9-91a4-2d25c5fb192b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8974fe05-862b-43f9-91a4-2d25c5fb192b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
              "0          US     42605767  R3EFW2STIYIY0I  B00MUTIDKI       248732228   \n",
              "1          US     51771800  R12NR0R5A9F7FT  B00EPACNUG       531462352   \n",
              "2          US     16053526  R1LSH74R9XAP59  B00164AZA4       473982505   \n",
              "3          US     15319481  R1QXUNTF76K7L6  B00E6LIEFM       189774198   \n",
              "4          US      1441820  R2F7DR75PS8NKT  B00VWEBG06       852470365   \n",
              "\n",
              "                                       product_title product_category  \\\n",
              "0       McAfee 2015 Internet Security 3 PC (3-Users)         Software   \n",
              "1                          Hallmark Card Studio 2014         Software   \n",
              "2                                Search and Rescue 4         Software   \n",
              "3                                     Quickbooks Pro         Software   \n",
              "4  Windows 7 Professional with Service Pack 1 (64...         Software   \n",
              "\n",
              "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
              "0            1              2            2    N                 Y   \n",
              "1            5              0            0    N                 Y   \n",
              "2            2              0            1    N                 Y   \n",
              "3            2              0            0    N                 Y   \n",
              "4            5              0            0    N                 Y   \n",
              "\n",
              "                                     review_headline  \\\n",
              "0                  I was very disappointed with this   \n",
              "1                                         Five Stars   \n",
              "2                                   Have windows 10?   \n",
              "3  Disc was corrupt, had to spend a couple hours ...   \n",
              "4                                         Five Stars   \n",
              "\n",
              "                                         review_body review_date  \n",
              "0  I was very disappointed with this. The descrip...  2015-08-31  \n",
              "1  I had a little struggle getting familiarized, ...  2015-08-31  \n",
              "2  Tried to download it on my Windows 10 and it w...  2015-08-31  \n",
              "3  Disc was corrupt, had to spend a couple hours ...  2015-08-31  \n",
              "4  Just what I needed. Took a little longer to sh...  2015-08-31  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bIkvouRpSzg"
      },
      "source": [
        "We see that there are in total of 15 variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-2oDWtymmlE",
        "outputId": "14a801ea-7d78-466c-8f6f-277ddf169f3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "marketplace          object\n",
              "customer_id           int64\n",
              "review_id            object\n",
              "product_id           object\n",
              "product_parent        int64\n",
              "product_title        object\n",
              "product_category     object\n",
              "star_rating           int64\n",
              "helpful_votes         int64\n",
              "total_votes           int64\n",
              "vine                 object\n",
              "verified_purchase    object\n",
              "review_headline      object\n",
              "review_body          object\n",
              "review_date          object\n",
              "dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjhUAuD2pa5P"
      },
      "source": [
        "Since we only require \"review_body\" and \"star_rating\". We can drop the other variables in our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx5yto7TiyaR"
      },
      "outputs": [],
      "source": [
        "df.drop(\"marketplace\", axis = 1, inplace = True)\n",
        "df.drop(\"customer_id\", axis = 1, inplace = True)\n",
        "df.drop(\"review_id\", axis = 1, inplace = True)\n",
        "df.drop(\"product_id\", axis = 1, inplace = True)\n",
        "df.drop(\"product_parent\", axis = 1, inplace = True)\n",
        "df.drop(\"product_title\", axis = 1, inplace = True)\n",
        "df.drop(\"product_category\",axis = 1, inplace = True)\n",
        "df.drop(\"helpful_votes\",axis = 1, inplace = True)\n",
        "df.drop(\"total_votes\",axis = 1, inplace = True)\n",
        "df.drop(\"vine\",axis = 1, inplace = True)\n",
        "df.drop(\"verified_purchase\",axis = 1, inplace = True)\n",
        "df.drop(\"review_headline\",axis = 1, inplace = True)\n",
        "df.drop(\"review_date\",axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAOPtqaFpl2W"
      },
      "source": [
        "The dataset becomes much clearer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bwGUs3DHm2_a",
        "outputId": "102a7892-47df-4cb0-e891-c1c32dd0444c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fd73ea32-918d-4841-b92e-5185c05372f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>star_rating</th>\n",
              "      <th>review_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>I was very disappointed with this. The descrip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>I had a little struggle getting familiarized, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Tried to download it on my Windows 10 and it w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Disc was corrupt, had to spend a couple hours ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Just what I needed. Took a little longer to sh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd73ea32-918d-4841-b92e-5185c05372f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd73ea32-918d-4841-b92e-5185c05372f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd73ea32-918d-4841-b92e-5185c05372f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   star_rating                                        review_body\n",
              "0            1  I was very disappointed with this. The descrip...\n",
              "1            5  I had a little struggle getting familiarized, ...\n",
              "2            2  Tried to download it on my Windows 10 and it w...\n",
              "3            2  Disc was corrupt, had to spend a couple hours ...\n",
              "4            5  Just what I needed. Took a little longer to sh..."
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNwBfV3juZf3"
      },
      "source": [
        "We then checked the frequency of each values of \"star_rating\". The graph shows that the value of '5' is almost twice of the value of '1' and outweight other values. This is not good for Machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "5Qqz4VdltXFh",
        "outputId": "59efc8e8-68db-4401-a3c0-c4f67f8367c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5    153572\n",
              "1     73867\n",
              "4     58556\n",
              "3     30639\n",
              "2     24615\n",
              "Name: star_rating, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.bar(*np.unique(df[\"star_rating\"], return_counts=True),color='purple', edgecolor='black')\n",
        "df.star_rating.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_xbELfXx8ox"
      },
      "source": [
        "Firstly I drop rows with missing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEz1JRzCyBBa"
      },
      "source": [
        "Secondly, I created an empty dataframe that collected 20000 data for each value of \"star_rating\". "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjYzT424vikC"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()\n",
        "sample_size = 20000\n",
        "df_equal = pd.DataFrame()\n",
        "for i in df.star_rating.unique():\n",
        "  X = df[df.star_rating == i].sample(sample_size)\n",
        "  df_equal = df_equal.append(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "pnZvaXbYxeEC",
        "outputId": "2195d3d7-2b3d-47ab-c231-373604f88c39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    20000\n",
              "5    20000\n",
              "2    20000\n",
              "3    20000\n",
              "4    20000\n",
              "Name: star_rating, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.bar(*np.unique(df_equal[\"star_rating\"], return_counts=True),color='purple', edgecolor='black')\n",
        "df_equal.star_rating.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJOBLSQt7vMJ"
      },
      "source": [
        "Before applying those machine learning algorithms and NLP models, we have to first clean and reorganize the review_body to make the later process easier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjXxZ_mP7-ST"
      },
      "source": [
        "There are several options in cleaning the text. The first step is to remove all stopword such as \"to\", \"I\", \"the\" from the review. This function can be completed using the nltk.stopwords."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6FGvgK58oYw"
      },
      "source": [
        "The second option is to lemmatize the word. For example, we need to transform the word \"worst\" to \"bad\". This function is completed using the stemming function called PorterStemmer()."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last option is to split the text."
      ],
      "metadata": {
        "id": "2sSowwnCR6zo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbraDrBEBUO-"
      },
      "outputs": [],
      "source": [
        "def cleanText(raw_text, remove_stopwords=False, stemming=False, split_text=False):\n",
        "    text = BeautifulSoup(raw_text, 'lxml').get_text()  #remove html\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)  # remove non-character\n",
        "    words = letters_only.lower().split() # convert to lower case \n",
        "    \n",
        "    if remove_stopwords: # remove stopword\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "        \n",
        "    if stemming==True: # stemming\n",
        "#         stemmer = PorterStemmer()\n",
        "        stemmer = SnowballStemmer('english') \n",
        "        words = [stemmer.stem(w) for w in words]\n",
        "        \n",
        "    if split_text==True:  # split text\n",
        "        return (words)\n",
        "    \n",
        "    return( \" \".join(words)) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We add the clean data into the dataset"
      ],
      "metadata": {
        "id": "faE_vM0WSDOr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQsJwA1m6LMZ",
        "outputId": "1a8d160e-73e9-4dbf-939b-ecd6cb3a3c02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.amazon.com/review/R3MNZCE7DLN8K5/ref=cm_cr_pr_cmt?ie=UTF8&ASIN=B00EFRME1C#wasThisHelpful\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n"
          ]
        }
      ],
      "source": [
        "df_equal['clean_review'] = df_equal.review_body.apply(cleanText)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we apply the train_test_split to our dataset, stratifying based on \"star_rating\"."
      ],
      "metadata": {
        "id": "SapDVENASKlh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBKRUXec7Hph"
      },
      "outputs": [],
      "source": [
        "x = df_equal['clean_review']\n",
        "y = df_equal['star_rating']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3wW4ZAaBmoX"
      },
      "source": [
        "Another big transformation needed is word vectorization. The simplest way will be using Bag of Words. So I used TF-IDF(Term Frequency-Inverse Document Frequency) for our analysis. The specific vectorize method is TfidfVectorizer() using unigram and bigram."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following three pipelines are multinomial Navie Bayer model, SGD classifier, and Logistic regression respectively."
      ],
      "metadata": {
        "id": "vtxRThmfSeXh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFzF201P73OG"
      },
      "outputs": [],
      "source": [
        "mnb = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2))),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvxy1NLC8GL-"
      },
      "outputs": [],
      "source": [
        "sgd = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2))),\n",
        "                ('clf', SGDClassifier()),\n",
        "               ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nakRJq0W8LWM"
      },
      "outputs": [],
      "source": [
        "logreg = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2))),\n",
        "                ('clf', LogisticRegression(max_iter=500)),\n",
        "               ])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first two models may take 1 mins while the last logistic regression can take up to 10 mins. Sorry for the inconvenience."
      ],
      "metadata": {
        "id": "hzNa85kESthi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSB_2zeZDGui",
        "outputId": "49bd1b8d-eeb1-438f-df93-a9c8746a8280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4566\n",
            "[[2645 1251   68   29    7]\n",
            " [1146 2404  353   85   12]\n",
            " [ 611 1860  980  486   63]\n",
            " [ 286 1030  603 1669  412]\n",
            " [ 295  613  211 1447 1434]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.53      0.66      0.59      4000\n",
            "           2       0.34      0.60      0.43      4000\n",
            "           3       0.44      0.24      0.32      4000\n",
            "           4       0.45      0.42      0.43      4000\n",
            "           5       0.74      0.36      0.48      4000\n",
            "\n",
            "    accuracy                           0.46     20000\n",
            "   macro avg       0.50      0.46      0.45     20000\n",
            "weighted avg       0.50      0.46      0.45     20000\n",
            "\n",
            "0.4962\n",
            "[[3335  259  166   67  173]\n",
            " [1962  817  704  229  288]\n",
            " [ 896  540 1279  692  593]\n",
            " [ 248  152  542 1184 1874]\n",
            " [ 173   61  133  324 3309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      0.83      0.63      4000\n",
            "           2       0.45      0.20      0.28      4000\n",
            "           3       0.45      0.32      0.37      4000\n",
            "           4       0.47      0.30      0.36      4000\n",
            "           5       0.53      0.83      0.65      4000\n",
            "\n",
            "    accuracy                           0.50     20000\n",
            "   macro avg       0.48      0.50      0.46     20000\n",
            "weighted avg       0.48      0.50      0.46     20000\n",
            "\n",
            "0.52805\n",
            "[[2727  851  244   75  103]\n",
            " [1117 1695  858  200  130]\n",
            " [ 456  896 1666  711  271]\n",
            " [ 128  230  813 1724 1105]\n",
            " [ 121  104  211  815 2749]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.60      0.68      0.64      4000\n",
            "           2       0.45      0.42      0.44      4000\n",
            "           3       0.44      0.42      0.43      4000\n",
            "           4       0.49      0.43      0.46      4000\n",
            "           5       0.63      0.69      0.66      4000\n",
            "\n",
            "    accuracy                           0.53     20000\n",
            "   macro avg       0.52      0.53      0.52     20000\n",
            "weighted avg       0.52      0.53      0.52     20000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Multinomial Naive Bayes\n",
        "mnb.fit(x_train, y_train)\n",
        "y_pred_mnb = mnb.predict(x_test)\n",
        "print(accuracy_score(y_test, y_pred_mnb))\n",
        "print(confusion_matrix(y_test, y_pred_mnb))\n",
        "print(classification_report(y_test, y_pred_mnb))\n",
        "\n",
        "# SGD Classifier\n",
        "sgd.fit(x_train, y_train)\n",
        "y_pred_sgd = sgd.predict(x_test)\n",
        "print(accuracy_score(y_test, y_pred_sgd))\n",
        "print(confusion_matrix(y_test, y_pred_sgd))\n",
        "print(classification_report(y_test, y_pred_sgd))\n",
        "\n",
        "# Logistic Regression\n",
        "logreg.fit(x_train, y_train)\n",
        "y_pred_log = logreg.predict(x_test)\n",
        "print(accuracy_score(y_test, y_pred_log))\n",
        "print(confusion_matrix(y_test, y_pred_log))\n",
        "print(classification_report(y_test, y_pred_log))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy for those three models are 0.4566, 0.4962, and 0.528. We see that accuracy of 1-star and 5-star are much higher than the middle ratings. This is because it is hard to set a standard for everyone in those ratings. Extreme reviews are more easily identified. We set these three models as a baseline and explore some other word vectorized method."
      ],
      "metadata": {
        "id": "RRQmh-U1S29D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One famous words vectorized method is using Word2Vec, but firstly we need to import the tokenizer from nltk to help us extract word from sentences.\n",
        "\n"
      ],
      "metadata": {
        "id": "5kSGt1sgTYtt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT4Id7mfZP-3"
      },
      "outputs": [],
      "source": [
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function parse text into sentences."
      ],
      "metadata": {
        "id": "wsfV50aBTsdP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKlwumedaw43"
      },
      "outputs": [],
      "source": [
        "def parseSent(review, tokenizer):\n",
        "    raw_sentences = tokenizer.tokenize(review.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append(cleanText(raw_sentence, remove_stopwords = True, split_text = True))\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created a list called sentences that will be used to prepare the Word2Vec vocabulary list."
      ],
      "metadata": {
        "id": "X_tV0-VtTyT7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3o_aTywdFEH",
        "outputId": "55e1b97b-4480-45c1-bbc4-72966ec63711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79978 parsed sentence in the training set\n",
            "\n",
            "Show a parsed sentence in the training set : \n",
            " ['use', 'pdf', 'converter', 'work', 'works', 'great', 'job', 'accountant', 'formating', 'adding', 'notes', 'reports', 'figured', 'give', 'shot', 'home', 'computer', 'big', 'mistake', 'seem', 'run', 'efficiently', 'laptop', 'even', 'shortcut', 'redaction', 'tool', 'bars', 'reviews', 'say', 'needs', 'enterprise', 'version', 'actually', 'think', 'version', 'might', 'better', 'one', 'installed', 'home', 'laptop', 'beefed', 'version', 'reader', 'tag', 'ocr', 'pdfs', 'exactly', 'best', 'ever', 'spent', 'paid', 'adobe', 'acrobat', 'standard']\n"
          ]
        }
      ],
      "source": [
        "sentences = []\n",
        "for review in x_train:\n",
        "    sentences += parseSent(review, tokenizer)\n",
        "print('%d parsed sentence in the training set\\n'  %len(sentences))\n",
        "print('Show a parsed sentence in the training set : \\n',  sentences[10])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using those sentences from the train set, we train a vocabulary list that helps us better classify reviews in the following neural network training."
      ],
      "metadata": {
        "id": "vk9j9QRGT828"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18HKTjBwdffE",
        "outputId": "35173c0c-a8b7-4891-b7b8-d15e129dfc64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Word2Vec model ...\n",
            "\n",
            "Number of words in the vocabulary list : 13979 \n",
            "\n",
            "Show first 10 words in the vocalbulary list  vocabulary list: \n",
            " ['software', 'program', 'use', 'product', 'version', 'would', 'one', 'get', 'windows', 'like']\n"
          ]
        }
      ],
      "source": [
        "num_features = 300  #embedding dimension                     \n",
        "min_word_count = 10                \n",
        "num_workers = 4       \n",
        "context = 10                                                                                          \n",
        "downsampling = 1e-3 \n",
        "\n",
        "print(\"Training Word2Vec model ...\\n\")\n",
        "w2v = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count,\\\n",
        "                 window = context, sample = downsampling)\n",
        "w2v.init_sims(replace=True)\n",
        "w2v.save(\"w2v_300features_10minwordcounts_10context\") #save trained word2vec model\n",
        "\n",
        "print(\"Number of words in the vocabulary list : %d \\n\" %len(w2v.wv.index2word))\n",
        "print(\"Show first 10 words in the vocalbulary list  vocabulary list: \\n\", w2v.wv.index2word[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW4lpFk4g2op",
        "outputId": "a61b28b0-63dd-4f03-b4c1-0a370a89f7c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of embedding matrix :  (13979, 300)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# Get Word2Vec embedding matrix\n",
        "embedding_matrix = w2v.wv.syn0  # embedding matrix, type = numpy.ndarray \n",
        "print(\"Shape of embedding matrix : \", embedding_matrix.shape) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The neural network I used is the LSTM model under the RNN catagory. I transfer the input(reviews) to numerical sequences using the trained tokenizer."
      ],
      "metadata": {
        "id": "OX2ZUq7MURCB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lwKWwOjkj38",
        "outputId": "b83d418e-6b97-47fe-a9be-274d81a3dd09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (80000, 100)\n",
            "x_test shape: (20000, 100)\n",
            "y_train shape: (80000, 6)\n",
            "y_test shape: (20000, 6)\n"
          ]
        }
      ],
      "source": [
        "top_words = embedding_matrix.shape[0]\n",
        "maxlen = 100 \n",
        "nb_classes = 6\n",
        "\n",
        "\n",
        "# Vectorize X_train and X_test to 2D tensor\n",
        "tokenizer = Tokenizer(nb_words=top_words) #only consider top 20000 words in the corpse\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "# tokenizer.word_index #access word-to-index dictionary of trained tokenizer\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "x_train_seq = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
        "x_test_seq = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n",
        "\n",
        "\n",
        "# one-hot encoding of y_train and y_test\n",
        "y_train_seq = np_utils.to_categorical(y_train, nb_classes)\n",
        "y_test_seq = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "print('x_train shape:', x_train_seq.shape) \n",
        "print('x_test shape:', x_test_seq.shape) \n",
        "print('y_train shape:', y_train_seq.shape) \n",
        "print('y_test shape:', y_test_seq.shape) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is the specific of the model. I used the \"adam\" optimizer for the training."
      ],
      "metadata": {
        "id": "_6bH5SPpUpIb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHTaUEbilM3C",
        "outputId": "40f60cd6-8e74-4309-f638-e8e0b3c56eff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 300)         4193700   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               219648    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 774       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,414,122\n",
            "Trainable params: 4,414,122\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "200/200 [==============================] - 89s 426ms/step - loss: 1.3764 - accuracy: 0.3802 - val_loss: 1.2079 - val_accuracy: 0.4656\n",
            "Epoch 2/3\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 1.1557 - accuracy: 0.4981 - val_loss: 1.1955 - val_accuracy: 0.4841\n",
            "Epoch 3/3\n",
            "200/200 [==============================] - 85s 426ms/step - loss: 1.0787 - accuracy: 0.5415 - val_loss: 1.1749 - val_accuracy: 0.4897\n"
          ]
        }
      ],
      "source": [
        "embedding_layer = Embedding(embedding_matrix.shape[0], \n",
        "                            embedding_matrix.shape[1], \n",
        "                            weights=[embedding_matrix])\n",
        "\n",
        "\n",
        "# Construct LSTM with Word2Vec embedding\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2)) \n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_seq, y_train_seq, batch_size=400, epochs=3, verbose=1, validation_data = (x_test_seq, y_test_seq))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final accuray for this model is 0.4897, which is close to the SGD classifier. For this model, it is very easy to overfit, so I only choose to use 3 epoch. I have looked up other examples doing a binary classification of positive reviews and negative reviews. The accuracy of the binary classification can reach over 90%. "
      ],
      "metadata": {
        "id": "nFm1zAT9UxhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The conclusion is that the logistic model provides the highest accuracy in the multi-classification task. The word2vec method's limitation may due to the variation of the words. It is easy to reach an accuracy of 70% for the training set with the train set vocabulary. However, the testing set accuracy drop after the training set accuracy reach 60%. It may be better to generate a vocabulary list using a very large trainset and then apply to the test set."
      ],
      "metadata": {
        "id": "URHdnrm4V4_2"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MATH4480 Final Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}